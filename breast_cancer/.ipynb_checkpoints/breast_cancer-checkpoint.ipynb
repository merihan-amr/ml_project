{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data from Files\n",
    "Load the data from the WDBC.DATA and WDBC.NAMES files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m attribute_info_index \u001b[38;5;241m=\u001b[39m lines\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m7. Attribute information\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m attribute_names \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines[attribute_info_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:attribute_info_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m31\u001b[39m]]\n\u001b[1;32m---> 14\u001b[0m attribute_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiagnosis\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m [name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attribute_names]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Assign column names to the DataFrame\u001b[39;00m\n\u001b[0;32m     17\u001b[0m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m attribute_names\n",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     12\u001b[0m attribute_info_index \u001b[38;5;241m=\u001b[39m lines\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m7. Attribute information\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m attribute_names \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines[attribute_info_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:attribute_info_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m31\u001b[39m]]\n\u001b[1;32m---> 14\u001b[0m attribute_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiagnosis\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m [\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attribute_names]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Assign column names to the DataFrame\u001b[39;00m\n\u001b[0;32m     17\u001b[0m data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m attribute_names\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Load Data from Files\n",
    "\n",
    "# Load the data from WDBC.DATA file\n",
    "data = pd.read_csv('WDBC.DATA', header=None)\n",
    "\n",
    "# Load the attribute names from WDBC.NAMES file\n",
    "with open('WDBC.NAMES', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Extract attribute names\n",
    "if '7. Attribute information\\n' in lines:\n",
    "    attribute_info_index = lines.index('7. Attribute information\\n')\n",
    "    attribute_names = [line.strip() for line in lines[attribute_info_index + 1:attribute_info_index + 31]]\n",
    "    attribute_names = ['ID', 'Diagnosis'] + [name.split(' ')[1] for name in attribute_names]\n",
    "\n",
    "    # Assign column names to the DataFrame\n",
    "    data.columns = attribute_names\n",
    "\n",
    "    # Display the first few rows of the DataFrame\n",
    "    data.head()\n",
    "else:\n",
    "    print(\"Attribute information not found in the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ta) radius (mean of distances from center to points on the perimeter)\\n',\n",
       " '\\tb) texture (standard deviation of gray-scale values)\\n',\n",
       " '\\tc) perimeter\\n',\n",
       " '\\td) area\\n',\n",
       " '\\te) smoothness (local variation in radius lengths)\\n',\n",
       " '\\tf) compactness (perimeter^2 / area - 1.0)\\n',\n",
       " '\\tg) concavity (severity of concave portions of the contour)\\n',\n",
       " '\\th) concave points (number of concave portions of the contour)\\n',\n",
       " '\\ti) symmetry \\n',\n",
       " '\\tj) fractal dimension (\"coastline approximation\" - 1)\\n']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_element=lines.index('\\ta) radius (mean of distances from center to points on the perimeter)\\n',)\n",
    "attribute_names= lines[a:a+10]\n",
    "attribute_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataFrame\n",
    "Parse the loaded data and create a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       569 non-null    int64  \n",
      " 1   1       569 non-null    object \n",
      " 2   2       569 non-null    float64\n",
      " 3   3       569 non-null    float64\n",
      " 4   4       569 non-null    float64\n",
      " 5   5       569 non-null    float64\n",
      " 6   6       569 non-null    float64\n",
      " 7   7       569 non-null    float64\n",
      " 8   8       569 non-null    float64\n",
      " 9   9       569 non-null    float64\n",
      " 10  10      569 non-null    float64\n",
      " 11  11      569 non-null    float64\n",
      " 12  12      569 non-null    float64\n",
      " 13  13      569 non-null    float64\n",
      " 14  14      569 non-null    float64\n",
      " 15  15      569 non-null    float64\n",
      " 16  16      569 non-null    float64\n",
      " 17  17      569 non-null    float64\n",
      " 18  18      569 non-null    float64\n",
      " 19  19      569 non-null    float64\n",
      " 20  20      569 non-null    float64\n",
      " 21  21      569 non-null    float64\n",
      " 22  22      569 non-null    float64\n",
      " 23  23      569 non-null    float64\n",
      " 24  24      569 non-null    float64\n",
      " 25  25      569 non-null    float64\n",
      " 26  26      569 non-null    float64\n",
      " 27  27      569 non-null    float64\n",
      " 28  28      569 non-null    float64\n",
      " 29  29      569 non-null    float64\n",
      " 30  30      569 non-null    float64\n",
      " 31  31      569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "# Parse the loaded data and create a pandas DataFrame\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "# data.head()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display DataFrame\n",
    "Display the first few rows of the DataFrame to verify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Title: Wisconsin Diagnostic Breast Cancer (WDBC)\\n',\n",
       " '\\n',\n",
       " '2. Source Information\\n',\n",
       " '\\n',\n",
       " 'a) Creators: \\n',\n",
       " '\\n',\n",
       " '\\tDr. William H. Wolberg, General Surgery Dept., University of\\n',\n",
       " '\\tWisconsin,  Clinical Sciences Center, Madison, WI 53792\\n',\n",
       " '\\twolberg@eagle.surgery.wisc.edu\\n',\n",
       " '\\n',\n",
       " '\\tW. Nick Street, Computer Sciences Dept., University of\\n',\n",
       " '\\tWisconsin, 1210 West Dayton St., Madison, WI 53706\\n',\n",
       " '\\tstreet@cs.wisc.edu  608-262-6619\\n',\n",
       " '\\n',\n",
       " '\\tOlvi L. Mangasarian, Computer Sciences Dept., University of\\n',\n",
       " '\\tWisconsin, 1210 West Dayton St., Madison, WI 53706\\n',\n",
       " '\\tolvi@cs.wisc.edu \\n',\n",
       " '\\n',\n",
       " 'b) Donor: Nick Street\\n',\n",
       " '\\n',\n",
       " 'c) Date: November 1995\\n',\n",
       " '\\n',\n",
       " '3. Past Usage:\\n',\n",
       " '\\n',\n",
       " 'first usage:\\n',\n",
       " '\\n',\n",
       " '\\tW.N. Street, W.H. Wolberg and O.L. Mangasarian \\n',\n",
       " '\\tNuclear feature extraction for breast tumor diagnosis.\\n',\n",
       " '\\tIS&T/SPIE 1993 International Symposium on Electronic Imaging: Science\\n',\n",
       " '\\tand Technology, volume 1905, pages 861-870, San Jose, CA, 1993.\\n',\n",
       " '\\n',\n",
       " 'OR literature:\\n',\n",
       " '\\n',\n",
       " '\\tO.L. Mangasarian, W.N. Street and W.H. Wolberg. \\n',\n",
       " '\\tBreast cancer diagnosis and prognosis via linear programming. \\n',\n",
       " '\\tOperations Research, 43(4), pages 570-577, July-August 1995.\\n',\n",
       " '\\n',\n",
       " 'Medical literature:\\n',\n",
       " '\\n',\n",
       " '\\tW.H. Wolberg, W.N. Street, and O.L. Mangasarian. \\n',\n",
       " '\\tMachine learning techniques to diagnose breast cancer from\\n',\n",
       " '\\tfine-needle aspirates.  \\n',\n",
       " '\\tCancer Letters 77 (1994) 163-171.\\n',\n",
       " '\\n',\n",
       " '\\tW.H. Wolberg, W.N. Street, and O.L. Mangasarian. \\n',\n",
       " '\\tImage analysis and machine learning applied to breast cancer\\n',\n",
       " '\\tdiagnosis and prognosis.  \\n',\n",
       " '\\tAnalytical and Quantitative Cytology and Histology, Vol. 17\\n',\n",
       " '\\tNo. 2, pages 77-87, April 1995. \\n',\n",
       " '\\n',\n",
       " '\\tW.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. \\n',\n",
       " '\\tComputerized breast cancer diagnosis and prognosis from fine\\n',\n",
       " '\\tneedle aspirates.  \\n',\n",
       " '\\tArchives of Surgery 1995;130:511-516.\\n',\n",
       " '\\n',\n",
       " '\\tW.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. \\n',\n",
       " '\\tComputer-derived nuclear features distinguish malignant from\\n',\n",
       " '\\tbenign breast cytology.  \\n',\n",
       " '\\tHuman Pathology, 26:792--796, 1995.\\n',\n",
       " '\\n',\n",
       " 'See also:\\n',\n",
       " '\\thttp://www.cs.wisc.edu/~olvi/uwmp/mpml.html\\n',\n",
       " '\\thttp://www.cs.wisc.edu/~olvi/uwmp/cancer.html\\n',\n",
       " '\\n',\n",
       " 'Results:\\n',\n",
       " '\\n',\n",
       " '\\t- predicting field 2, diagnosis: B = benign, M = malignant\\n',\n",
       " '\\t- sets are linearly separable using all 30 input features\\n',\n",
       " '\\t- best predictive accuracy obtained using one separating plane\\n',\n",
       " '\\t\\tin the 3-D space of Worst Area, Worst Smoothness and\\n',\n",
       " '\\t\\tMean Texture.  Estimated accuracy 97.5% using repeated\\n',\n",
       " '\\t\\t10-fold crossvalidations.  Classifier has correctly\\n',\n",
       " '\\t\\tdiagnosed 176 consecutive new patients as of November\\n',\n",
       " '\\t\\t1995. \\n',\n",
       " '\\n',\n",
       " '4. Relevant information\\n',\n",
       " '\\n',\n",
       " '\\tFeatures are computed from a digitized image of a fine needle\\n',\n",
       " '\\taspirate (FNA) of a breast mass.  They describe\\n',\n",
       " '\\tcharacteristics of the cell nuclei present in the image.\\n',\n",
       " '\\tA few of the images can be found at\\n',\n",
       " '\\thttp://www.cs.wisc.edu/~street/images/\\n',\n",
       " '\\n',\n",
       " '\\tSeparating plane described above was obtained using\\n',\n",
       " '\\tMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\n',\n",
       " '\\tConstruction Via Linear Programming.\" Proceedings of the 4th\\n',\n",
       " '\\tMidwest Artificial Intelligence and Cognitive Science Society,\\n',\n",
       " '\\tpp. 97-101, 1992], a classification method which uses linear\\n',\n",
       " '\\tprogramming to construct a decision tree.  Relevant features\\n',\n",
       " '\\twere selected using an exhaustive search in the space of 1-4\\n',\n",
       " '\\tfeatures and 1-3 separating planes.\\n',\n",
       " '\\n',\n",
       " '\\tThe actual linear program used to obtain the separating plane\\n',\n",
       " '\\tin the 3-dimensional space is that described in:\\n',\n",
       " '\\t[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\n',\n",
       " '\\tProgramming Discrimination of Two Linearly Inseparable Sets\",\\n',\n",
       " '\\tOptimization Methods and Software 1, 1992, 23-34].\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\tThis database is also available through the UW CS ftp server:\\n',\n",
       " '\\n',\n",
       " '\\tftp ftp.cs.wisc.edu\\n',\n",
       " '\\tcd math-prog/cpo-dataset/machine-learn/WDBC/\\n',\n",
       " '\\n',\n",
       " '5. Number of instances: 569 \\n',\n",
       " '\\n',\n",
       " '6. Number of attributes: 32 (ID, diagnosis, 30 real-valued input features)\\n',\n",
       " '\\n',\n",
       " '7. Attribute information\\n',\n",
       " '\\n',\n",
       " '1) ID number\\n',\n",
       " '2) Diagnosis (M = malignant, B = benign)\\n',\n",
       " '3-32)\\n',\n",
       " '\\n',\n",
       " 'Ten real-valued features are computed for each cell nucleus:\\n',\n",
       " '\\n',\n",
       " '\\ta) radius (mean of distances from center to points on the perimeter)\\n',\n",
       " '\\tb) texture (standard deviation of gray-scale values)\\n',\n",
       " '\\tc) perimeter\\n',\n",
       " '\\td) area\\n',\n",
       " '\\te) smoothness (local variation in radius lengths)\\n',\n",
       " '\\tf) compactness (perimeter^2 / area - 1.0)\\n',\n",
       " '\\tg) concavity (severity of concave portions of the contour)\\n',\n",
       " '\\th) concave points (number of concave portions of the contour)\\n',\n",
       " '\\ti) symmetry \\n',\n",
       " '\\tj) fractal dimension (\"coastline approximation\" - 1)\\n',\n",
       " '\\n',\n",
       " 'Several of the papers listed above contain detailed descriptions of\\n',\n",
       " 'how these features are computed. \\n',\n",
       " '\\n',\n",
       " 'The mean, standard error, and \"worst\" or largest (mean of the three\\n',\n",
       " 'largest values) of these features were computed for each image,\\n',\n",
       " 'resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n',\n",
       " '13 is Radius SE, field 23 is Worst Radius.\\n',\n",
       " '\\n',\n",
       " 'All feature values are recoded with four significant digits.\\n',\n",
       " '\\n',\n",
       " '8. Missing attribute values: none\\n',\n",
       " '\\n',\n",
       " '9. Class distribution: 357 benign, 212 malignant']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display DataFrame\n",
    "# Display the first few rows of the DataFrame to verify the data\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('WDBC.DATA',header=None)\n",
    "df.columns=['ID','Diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean','compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean','radius_se','texture_se','perimeter_se','area_se','smoothness_se','compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se','radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst','compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2= pd.read_csv('data.csv')\n",
    "df2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
