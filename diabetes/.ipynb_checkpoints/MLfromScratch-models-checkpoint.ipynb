{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f097da31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            2      138             62             35        0  33.6   \n",
      "1            0       84             82             31      125  38.2   \n",
      "2            0      145              0              0        0  44.2   \n",
      "3            0      135             68             42      250  42.3   \n",
      "4            1      139             62             41      480  40.7   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.127   47        1  \n",
      "1                     0.233   23        0  \n",
      "2                     0.630   31        1  \n",
      "3                     0.365   24        1  \n",
      "4                     0.536   21        0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data=pd.read_csv(\"diabetes3.csv\")\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067a1ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build logistic regression model to predict the class\n",
    "from mlfromscratch import train_test_split_2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "scaler = StandardScaler2()\n",
    "X = scaler.fit_transform(X)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test=train_test_split_2(X,y,random_state=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db44bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlfromscratch import LogisticRegressionMultiClass\n",
    "\n",
    "model = LogisticRegressionMultiClass()\n",
    "\n",
    "model.fit(X_train, y_train.to_numpy().astype(int))\n",
    "ypred=model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm=confusion_matrix(y_test,ypred)\n",
    "acc=accuracy_score(y_test,ypred)\n",
    "print(cm)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8cd5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build logistic regression model to predict the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8f7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8fb930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build decision tree model to predict the class\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c913726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc74734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array and ensure float type\n",
    "\n",
    "from mlfromscratch import DecisionTree\n",
    "X_train = X_train.values.astype(np.float64)\n",
    "X_test = X_test.values.astype(np.float64)\n",
    "DT_cl = DecisionTree()\n",
    "DT_cl.fit(X_train, y_train)\n",
    "y_pred_2 = DT_cl.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred_2)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build random forest model to predict the class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea936ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eb0cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build KNN model to predict the class\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure numpy and pandas are up to date\n",
    "# %pip install --upgrade numpy pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e7be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlfromscratch import KNNClassifier\n",
    "knn_cl=KNNClassifier()\n",
    "knn_cl.fit(X_train,y_train)\n",
    "ypred=knn_cl.predict(X_test)\n",
    "acc=accuracy_score(y_test,ypred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c862ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build Bayesian model to predict the class\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d0614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6607a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Convert to numpy array and ensure float type\n",
    "#its required to convert the data to numpy array before using the model\n",
    "# X_train = X_train.values.astype(np.float64)\n",
    "# X_test = X_test.values.astype(np.float64)\n",
    "from mlfromscratch import GaussianNaiveBayes\n",
    "NB = GaussianNaiveBayes()\n",
    "NB.fit(X_train, y_train)\n",
    "y_pred = NB.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b7536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SVMClassifier:\n",
    "    def __init__(self, learning_rate=0.01, lambda_param=0.01, n_iters=4000):\n",
    "        \"\"\"\n",
    "        Initialize the SVM Classifier.\n",
    "\n",
    "        Parameters:\n",
    "        - learning_rate: Step size for gradient descent.\n",
    "        - lambda_param: Regularization parameter.\n",
    "        - n_iters: Number of iterations for training.\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_param = lambda_param\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the SVM Classifier using Stochastic Gradient Descent (SGD).\n",
    "\n",
    "        Parameters:\n",
    "        - X: Training features (n_samples, n_features). Can be a NumPy array or pandas DataFrame.\n",
    "        - y: Target labels (n_samples,). Can be a NumPy array or pandas Series.\n",
    "        \"\"\"\n",
    "        # Convert inputs to NumPy arrays if they are pandas DataFrames/Series\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Initialize weights and bias\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # Convert labels to -1 and 1 for SVM\n",
    "        y_ = np.where(y <= 0, -1, 1)\n",
    "\n",
    "        # Stochastic Gradient Descent\n",
    "        for _ in range(self.n_iters):\n",
    "            for i in range(n_samples):\n",
    "                # Check if the sample is correctly classified\n",
    "                condition = y_[i] * (np.dot(X[i], self.weights) - self.bias) >= 1\n",
    "\n",
    "                # Update weights and bias based on the hinge loss\n",
    "                if condition:\n",
    "                    self.weights -= self.learning_rate * (2 * self.lambda_param * self.weights)\n",
    "                else:\n",
    "                    self.weights -= self.learning_rate * (\n",
    "                        2 * self.lambda_param * self.weights - np.dot(X[i], y_[i])\n",
    "                    )\n",
    "                    self.bias -= self.learning_rate * y_[i]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class labels for the test data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Test features (n_samples, n_features). Can be a NumPy array or pandas DataFrame.\n",
    "\n",
    "        Returns:\n",
    "        - Predicted class labels (n_samples,) as 0 or 1.\n",
    "        \"\"\"\n",
    "        # Convert input to NumPy array if it is a pandas DataFrame\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "\n",
    "        # Compute the decision function\n",
    "        decision_function = np.dot(X, self.weights) - self.bias\n",
    "\n",
    "        # Convert predictions to 0 or 1\n",
    "        return np.where(decision_function <= 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm=SVMClassifier()\n",
    "svm.fit(X_train,y_train)\n",
    "ypred=svm.predict(X_test)\n",
    "acc3=accuracy_score(y_test,ypred)\n",
    "acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7ae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlfromscratch import StandardScaler2\n",
    "scaler = StandardScaler2()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
